---
title: "Database Design Guidelines for SaaS Applications"
description: "Detailed explanations of database design for SaaS applications considering multi-tenancy, scalability, and security. Implementation examples using PostgreSQL and Prisma are also included."
publishedAt: "2024-01-12"
updatedAt: "2024-01-25"
tags: ["Database", "SaaS", "PostgreSQL", "Design", "Scalability", "Security"]
category: "Technology"
author: "Keiko Tanaka"
authorAvatar: "/avatars/keiko-tanaka.jpg"
coverImage: "https://images.unsplash.com/photo-1558494949-ef010cbdcc31?ixlib=rb-4.0.3&ixid=M3wxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8fA%3D%3D&auto=format&fit=crop&w=2070&q=80"
featured: true
draft: false

# === AI/RAG用メタデータ ===
ai:
  keywords:
    - "データベース設計"
    - "SaaS"
    - "マルチテナント"
    - "PostgreSQL"
    - "Prisma"
    - "Row Level Security"
    - "RLS"
    - "パーティショニング"
    - "セキュリティ"
    - "監査ログ"
  relatedQuestions:
    - "SaaSのマルチテナント設計はどうする？"
    - "PostgreSQLでRLSを実装するには？"
    - "Prismaでマルチテナント対応するには？"
    - "SaaSのデータベースセキュリティ対策は？"
    - "監査ログの実装方法は？"
  prerequisites:
    - "SQLの基本知識"
    - "PostgreSQLの基本"
    - "SaaSアプリケーションの概念理解"
  relatedDocs:
    - "/docs/best-practices"
    - "/docs/authentication"
  aiSummary: |
    SaaSアプリケーションのデータベース設計ガイドライン。
    マルチテナント戦略（行レベル分離、スキーマ分離、DB分離）の比較、
    PostgreSQLのRow Level Security (RLS)実装、Prismaスキーマ例、
    監査ログ、使用量追跡、セキュリティ対策を含む包括的なガイド。
  chunkStrategy: "h2"
  searchable: true
  difficulty: "advanced"
  contentType: "guide"
---

# Database Design Guidelines for SaaS Applications

In the success of SaaS applications, database design is a critically important element. Proper design ensures scalability, security, and performance, while inadequate design becomes a barrier to future growth.

This article provides detailed explanations of database design best practices based on experience with SaaS applications running in actual production environments.

## Multi-Tenant Strategy Selection

The first important decision in SaaS applications is the selection of a multi-tenant strategy.

### 1. Comparison of Database Isolation Levels

| Strategy | Security | Cost | Management Complexity | Scalability |
|----------|----------|------|----------------------|-------------|
| Database Isolation | ★★★★★ | ★★☆☆☆ | ★★★★☆ | ★★★☆☆ |
| Schema Isolation | ★★★★☆ | ★★★☆☆ | ★★★☆☆ | ★★★★☆ |
| Row-Level Isolation | ★★★☆☆ | ★★★★★ | ★★★★★ | ★★★★★ |

### 2. Row-Level Isolation Implementation

Let's look at an implementation example of row-level isolation, which is the most common and cost-effective approach:

```sql
-- Tenant management table
CREATE TABLE tenants (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  name VARCHAR(255) NOT NULL,
  subdomain VARCHAR(100) UNIQUE NOT NULL,
  plan_type VARCHAR(50) NOT NULL DEFAULT 'free',
  created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
  updated_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
  is_active BOOLEAN DEFAULT TRUE,
  
  -- Configuration information
  settings JSONB DEFAULT '{}',
  
  -- Usage limits
  max_users INTEGER DEFAULT 5,
  max_storage_gb INTEGER DEFAULT 1,
  
  CONSTRAINT valid_subdomain 
    CHECK (subdomain ~ '^[a-z0-9][a-z0-9-]*[a-z0-9]$')
);

-- User table
CREATE TABLE users (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  tenant_id UUID NOT NULL REFERENCES tenants(id) ON DELETE CASCADE,
  email VARCHAR(255) NOT NULL,
  password_hash VARCHAR(255) NOT NULL,
  role VARCHAR(50) NOT NULL DEFAULT 'user',
  
  -- Profile information
  first_name VARCHAR(100),
  last_name VARCHAR(100),
  avatar_url TEXT,
  
  -- Status management
  is_active BOOLEAN DEFAULT TRUE,
  email_verified_at TIMESTAMP WITH TIME ZONE,
  last_login_at TIMESTAMP WITH TIME ZONE,
  
  created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
  updated_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
  
  UNIQUE(tenant_id, email)
);

-- Project table
CREATE TABLE projects (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  tenant_id UUID NOT NULL REFERENCES tenants(id) ON DELETE CASCADE,
  name VARCHAR(255) NOT NULL,
  description TEXT,
  
  -- Project settings
  settings JSONB DEFAULT '{}',
  
  -- Status management
  status VARCHAR(50) DEFAULT 'active',
  archived_at TIMESTAMP WITH TIME ZONE,
  
  created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
  updated_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
  created_by UUID REFERENCES users(id)
);
```

### 3. Row Level Security (RLS) Implementation

Leverage PostgreSQL's RLS to strengthen tenant isolation:

```sql
-- Enable RLS
ALTER TABLE users ENABLE ROW LEVEL SECURITY;
ALTER TABLE projects ENABLE ROW LEVEL SECURITY;

-- Policy for users
CREATE POLICY tenant_isolation_users ON users
  USING (tenant_id = current_setting('app.current_tenant_id')::UUID);

-- Policy for projects
CREATE POLICY tenant_isolation_projects ON projects
  USING (tenant_id = current_setting('app.current_tenant_id')::UUID);

-- Bypass policy for administrators
CREATE POLICY admin_bypass_users ON users
  TO admin_role
  USING (true);
```

## Scalable Schema Design

### 1. Efficient Index Strategy

```sql
-- Create composite indexes
CREATE INDEX idx_users_tenant_email ON users(tenant_id, email);
CREATE INDEX idx_projects_tenant_status ON projects(tenant_id, status);
CREATE INDEX idx_projects_created_at ON projects(created_at DESC);

-- Partial indexes (conditional indexes)
CREATE INDEX idx_active_users 
ON users(tenant_id, email) 
WHERE is_active = TRUE;

-- Expression indexes
CREATE INDEX idx_users_email_lower 
ON users(tenant_id, LOWER(email));

-- GIN indexes (for JSON search)
CREATE INDEX idx_tenant_settings 
ON tenants USING GIN(settings);
```

### 2. Partitioning Strategy

Efficient management of time-series data:

```sql
-- Partitioning of log table
CREATE TABLE audit_logs (
  id UUID DEFAULT gen_random_uuid(),
  tenant_id UUID NOT NULL,
  user_id UUID,
  action VARCHAR(100) NOT NULL,
  resource_type VARCHAR(100),
  resource_id UUID,
  details JSONB,
  ip_address INET,
  user_agent TEXT,
  created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW()
) PARTITION BY RANGE (created_at);

-- Create monthly partitions
CREATE TABLE audit_logs_2024_01 
PARTITION OF audit_logs
FOR VALUES FROM ('2024-01-01') TO ('2024-02-01');

CREATE TABLE audit_logs_2024_02 
PARTITION OF audit_logs
FOR VALUES FROM ('2024-02-01') TO ('2024-03-01');

-- Automatic partition creation function
CREATE OR REPLACE FUNCTION create_monthly_partition(table_name TEXT, start_date DATE)
RETURNS VOID AS $$
DECLARE
  partition_name TEXT;
  end_date DATE;
BEGIN
  partition_name := table_name || '_' || to_char(start_date, 'YYYY_MM');
  end_date := start_date + INTERVAL '1 month';
  
  EXECUTE format(
    'CREATE TABLE %I PARTITION OF %I FOR VALUES FROM (%L) TO (%L)',
    partition_name, table_name, start_date, end_date
  );
END;
$$ LANGUAGE plpgsql;
```

## Usage Limits and Resource Management

### 1. Per-Tenant Usage Tracking

```sql
-- Usage tracking table
CREATE TABLE usage_metrics (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  tenant_id UUID NOT NULL REFERENCES tenants(id),
  metric_name VARCHAR(100) NOT NULL,
  metric_value BIGINT NOT NULL,
  measured_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
  
  -- Metadata
  metadata JSONB DEFAULT '{}',
  
  UNIQUE(tenant_id, metric_name, measured_at)
);

-- Usage summary view
CREATE VIEW tenant_usage_summary AS
SELECT 
  t.id as tenant_id,
  t.name as tenant_name,
  t.plan_type,
  COALESCE(um_users.metric_value, 0) as current_users,
  t.max_users,
  COALESCE(um_storage.metric_value, 0) as storage_used_mb,
  (t.max_storage_gb * 1024) as storage_limit_mb,
  CASE 
    WHEN COALESCE(um_users.metric_value, 0) >= t.max_users THEN true
    WHEN COALESCE(um_storage.metric_value, 0) >= (t.max_storage_gb * 1024) THEN true
    ELSE false
  END as is_over_limit
FROM tenants t
LEFT JOIN LATERAL (
  SELECT metric_value 
  FROM usage_metrics 
  WHERE tenant_id = t.id 
    AND metric_name = 'active_users'
  ORDER BY measured_at DESC 
  LIMIT 1
) um_users ON true
LEFT JOIN LATERAL (
  SELECT metric_value 
  FROM usage_metrics 
  WHERE tenant_id = t.id 
    AND metric_name = 'storage_used_mb'
  ORDER BY measured_at DESC 
  LIMIT 1
) um_storage ON true;
```

### 2. Plan Limit Implementation

```sql
-- Plan definition table
CREATE TABLE subscription_plans (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  name VARCHAR(100) NOT NULL UNIQUE,
  display_name VARCHAR(255) NOT NULL,
  
  -- Limit values
  max_users INTEGER NOT NULL,
  max_storage_gb INTEGER NOT NULL,
  max_projects INTEGER NOT NULL,
  max_api_calls_per_month INTEGER NOT NULL,
  
  -- Feature flags
  features JSONB NOT NULL DEFAULT '{}',
  
  -- Pricing information
  price_monthly_cents INTEGER,
  price_annual_cents INTEGER,
  
  is_active BOOLEAN DEFAULT TRUE,
  created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW()
);

-- Plan-specific feature check function
CREATE OR REPLACE FUNCTION check_feature_access(
  p_tenant_id UUID,
  p_feature_name TEXT
) RETURNS BOOLEAN AS $$
DECLARE
  has_access BOOLEAN := FALSE;
BEGIN
  SELECT 
    COALESCE(sp.features->p_feature_name, 'false')::BOOLEAN
  INTO has_access
  FROM tenants t
  JOIN subscription_plans sp ON sp.name = t.plan_type
  WHERE t.id = p_tenant_id;
  
  RETURN COALESCE(has_access, FALSE);
END;
$$ LANGUAGE plpgsql;
```

## Security and Compliance

### 1. Data Encryption

```sql
-- Encrypted table for sensitive data
CREATE TABLE encrypted_secrets (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  tenant_id UUID NOT NULL REFERENCES tenants(id),
  key_name VARCHAR(255) NOT NULL,
  
  -- Encrypted data
  encrypted_value BYTEA NOT NULL,
  encryption_key_id VARCHAR(255) NOT NULL,
  
  -- Metadata
  created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
  updated_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
  created_by UUID REFERENCES users(id),
  
  UNIQUE(tenant_id, key_name)
);

-- Example encryption function (implement in application layer in practice)
CREATE OR REPLACE FUNCTION encrypt_secret(
  p_tenant_id UUID,
  p_key_name VARCHAR(255),
  p_plaintext TEXT,
  p_created_by UUID
) RETURNS UUID AS $$
DECLARE
  secret_id UUID;
BEGIN
  -- Actual encryption is performed in application layer
  INSERT INTO encrypted_secrets (
    tenant_id, key_name, encrypted_value, 
    encryption_key_id, created_by
  ) VALUES (
    p_tenant_id, p_key_name, 
    -- Example using pgcrypto (external KMS recommended for production)
    pgp_sym_encrypt(p_plaintext, current_setting('app.encryption_key')),
    'app_key_v1', p_created_by
  ) RETURNING id INTO secret_id;
  
  RETURN secret_id;
END;
$$ LANGUAGE plpgsql;
```

### 2. Audit Log Implementation

```sql
-- Comprehensive audit log
CREATE TABLE audit_logs (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  tenant_id UUID NOT NULL REFERENCES tenants(id),
  
  -- User information
  user_id UUID REFERENCES users(id),
  user_email VARCHAR(255),
  
  -- Action details
  action VARCHAR(100) NOT NULL, -- CREATE, UPDATE, DELETE, LOGIN, etc.
  resource_type VARCHAR(100) NOT NULL, -- user, project, file, etc.
  resource_id UUID,
  resource_name VARCHAR(255),
  
  -- Change details
  old_values JSONB,
  new_values JSONB,
  
  -- Request information
  ip_address INET,
  user_agent TEXT,
  request_id UUID,
  
  -- Metadata
  metadata JSONB DEFAULT '{}',
  
  created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW()
) PARTITION BY RANGE (created_at);

-- Trigger function for audit log creation
CREATE OR REPLACE FUNCTION create_audit_log()
RETURNS TRIGGER AS $$
BEGIN
  INSERT INTO audit_logs (
    tenant_id, user_id, action, resource_type, 
    resource_id, old_values, new_values
  ) VALUES (
    COALESCE(NEW.tenant_id, OLD.tenant_id),
    current_setting('app.current_user_id', true)::UUID,
    TG_OP,
    TG_TABLE_NAME,
    COALESCE(NEW.id, OLD.id),
    to_jsonb(OLD),
    to_jsonb(NEW)
  );
  
  RETURN COALESCE(NEW, OLD);
END;
$$ LANGUAGE plpgsql;

-- Apply triggers
CREATE TRIGGER audit_users_trigger
  AFTER INSERT OR UPDATE OR DELETE ON users
  FOR EACH ROW EXECUTE FUNCTION create_audit_log();
```

## Prisma Schema Implementation

Prisma schema for actual application use:

```prisma
// schema.prisma
generator client {
  provider = "prisma-client-js"
}

datasource db {
  provider = "postgresql"
  url      = env("DATABASE_URL")
}

model Tenant {
  id        String   @id @default(cuid())
  name      String
  subdomain String   @unique
  planType  String   @default("free") @map("plan_type")
  
  // Settings
  settings Json @default("{}")
  
  // Limits
  maxUsers     Int @default(5) @map("max_users")
  maxStorageGb Int @default(1) @map("max_storage_gb")
  
  // Status
  isActive  Boolean   @default(true) @map("is_active")
  createdAt DateTime  @default(now()) @map("created_at")
  updatedAt DateTime  @updatedAt @map("updated_at")
  
  // Relations
  users         User[]
  projects      Project[]
  usageMetrics  UsageMetric[]
  auditLogs     AuditLog[]
  
  @@map("tenants")
}

model User {
  id       String @id @default(cuid())
  tenantId String @map("tenant_id")
  email    String
  
  // Authentication
  passwordHash String @map("password_hash")
  role         String @default("user")
  
  // Profile
  firstName String? @map("first_name")
  lastName  String? @map("last_name")
  avatarUrl String? @map("avatar_url")
  
  // Status
  isActive         Boolean   @default(true) @map("is_active")
  emailVerifiedAt  DateTime? @map("email_verified_at")
  lastLoginAt      DateTime? @map("last_login_at")
  
  createdAt DateTime @default(now()) @map("created_at")
  updatedAt DateTime @updatedAt @map("updated_at")
  
  // Relations
  tenant        Tenant      @relation(fields: [tenantId], references: [id], onDelete: Cascade)
  createdProjects Project[] @relation("ProjectCreator")
  auditLogs     AuditLog[]
  
  @@unique([tenantId, email])
  @@map("users")
}

model Project {
  id          String  @id @default(cuid())
  tenantId    String  @map("tenant_id")
  name        String
  description String?
  
  // Settings
  settings Json @default("{}") 
  
  // Status
  status     String    @default("active")
  archivedAt DateTime? @map("archived_at")
  
  createdAt DateTime @default(now()) @map("created_at")
  updatedAt DateTime @updatedAt @map("updated_at")
  createdBy String?  @map("created_by")
  
  // Relations
  tenant  Tenant @relation(fields: [tenantId], references: [id], onDelete: Cascade)
  creator User?  @relation("ProjectCreator", fields: [createdBy], references: [id])
  
  @@map("projects")
}

model UsageMetric {
  id          String   @id @default(cuid())
  tenantId    String   @map("tenant_id")
  metricName  String   @map("metric_name")
  metricValue BigInt   @map("metric_value")
  measuredAt  DateTime @default(now()) @map("measured_at")
  
  // Metadata
  metadata Json @default("{}")
  
  // Relations
  tenant Tenant @relation(fields: [tenantId], references: [id], onDelete: Cascade)
  
  @@unique([tenantId, metricName, measuredAt])
  @@map("usage_metrics")
}

model AuditLog {
  id           String    @id @default(cuid())
  tenantId     String    @map("tenant_id")
  userId       String?   @map("user_id")
  action       String
  resourceType String    @map("resource_type")
  resourceId   String?   @map("resource_id")
  
  // Change details
  oldValues Json? @map("old_values")
  newValues Json? @map("new_values")
  
  // Request information
  ipAddress String? @map("ip_address")
  userAgent String? @map("user_agent")
  
  // Metadata
  metadata Json @default("{}")
  
  createdAt DateTime @default(now()) @map("created_at")
  
  // Relations
  tenant Tenant @relation(fields: [tenantId], references: [id], onDelete: Cascade)
  user   User?  @relation(fields: [userId], references: [id])
  
  @@map("audit_logs")
}
```

## Performance Optimization

### 1. Query Optimization Best Practices

```typescript
// Examples of efficient queries
class TenantService {
  async getTenantWithUsers(tenantId: string) {
    return await prisma.tenant.findUnique({
      where: { id: tenantId },
      include: {
        users: {
          where: { isActive: true },
          select: {
            id: true,
            email: true,
            firstName: true,
            lastName: true,
            role: true,
            lastLoginAt: true,
          },
          orderBy: { createdAt: 'desc' },
        },
        _count: {
          select: {
            projects: true,
            users: true,
          },
        },
      },
    })
  }

  // Batch processing optimization
  async getTenantsUsage(tenantIds: string[]) {
    const [tenants, usageMetrics] = await Promise.all([
      prisma.tenant.findMany({
        where: { id: { in: tenantIds } },
        select: {
          id: true,
          name: true,
          planType: true,
          maxUsers: true,
          maxStorageGb: true,
        },
      }),
      prisma.usageMetric.findMany({
        where: {
          tenantId: { in: tenantIds },
          metricName: { in: ['active_users', 'storage_used_mb'] },
        },
        orderBy: { measuredAt: 'desc' },
        distinct: ['tenantId', 'metricName'],
      }),
    ])

    // Data joining process
    return tenants.map(tenant => {
      const userUsage = usageMetrics.find(
        m => m.tenantId === tenant.id && m.metricName === 'active_users'
      )
      const storageUsage = usageMetrics.find(
        m => m.tenantId === tenant.id && m.metricName === 'storage_used_mb'
      )

      return {
        ...tenant,
        currentUsers: userUsage?.metricValue || 0,
        storageUsedMb: storageUsage?.metricValue || 0,
        isOverLimit: 
          (userUsage?.metricValue || 0) >= tenant.maxUsers ||
          (storageUsage?.metricValue || 0) >= (tenant.maxStorageGb * 1024),
      }
    })
  }
}
```

### 2. Connection Pool and Cache Strategy

```typescript
// Connection pool configuration
const prisma = new PrismaClient({
  datasources: {
    db: {
      url: process.env.DATABASE_URL,
    },
  },
  // Connection pool settings
  // connection_limit=10&pool_timeout=30
})

// Redis cache implementation
class CacheService {
  private redis: Redis

  async getTenantCached(tenantId: string): Promise<Tenant | null> {
    const cacheKey = `tenant:${tenantId}`
    
    // Get from cache
    const cached = await this.redis.get(cacheKey)
    if (cached) {
      return JSON.parse(cached)
    }

    // Get from database
    const tenant = await prisma.tenant.findUnique({
      where: { id: tenantId },
    })

    if (tenant) {
      // Save to cache (5 minutes)
      await this.redis.setex(cacheKey, 300, JSON.stringify(tenant))
    }

    return tenant
  }

  async invalidateTenantCache(tenantId: string): Promise<void> {
    await this.redis.del(`tenant:${tenantId}`)
  }
}
```

## Conclusion

For SaaS application database design, the following elements are crucial:

### Basic Design Principles

1. **Multi-tenant Strategy**: Choose appropriate isolation levels based on requirements
2. **Scalability**: Partitioning and indexing strategies
3. **Security**: Implement RLS, encryption, and audit logging
4. **Performance**: Efficient queries and appropriate caching strategies

### Implementation Considerations

<Callout type="info">
Database design is difficult to change later. Carefully consider the following in the initial stages:

- **Data Model Normalization**: Choose appropriate normalization levels
- **Index Strategy**: Design based on query patterns
- **Audit Requirements**: Confirm compliance requirements
- **Scalability**: Design with future growth in mind
</Callout>

### Continuous Optimization

1. **Monitoring and Metrics**: Continuous monitoring of query performance
2. **Index Optimization**: Adjustments based on usage patterns
3. **Capacity Planning**: Resource planning based on growth projections
4. **Security Audits**: Regular security reviews

With proper database design, you can build a scalable and secure foundation for SaaS applications. Continue to optimize based on changing requirements and aim for long-term success.